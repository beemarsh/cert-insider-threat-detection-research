{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce4de18b-bc8a-4140-bc97-117047a196ce",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The input dataset should already have a 'day' and 'is_working_hour column' defined which we already did.\n",
    "# We are using the chunks that we generated using the email_chunk_generator file\n",
    "\n",
    "# The output dataset has eight columns, 2 of which are user and day and 6 are calculated using this script\n",
    "# This script calculate four attributes from the email cert dataset. It generates the following attribute for each user for every single day\n",
    "# numAttachmentDay\n",
    "# numAttachmentNight\n",
    "# numEmailSentwithAttachDay\n",
    "# numEmailSentwithAttachNight\n",
    "# numEmailRecievedwithAttachDay\n",
    "# numEmailRecievedwithAttachNight\n",
    "\n",
    "# For this dataset calculation, I used HPC Cluster (Magnolia) from University of Southern Mississippi\n",
    "# In HPC clusters, I used Slrum Workload Manager, the script for which is also discussed somewhere in the repo\n",
    "\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f5c1a72-4799-411f-90f2-756768a1f2ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_folder_results = 'temp_results'  # Temporary folder to store intermediate result files\n",
    "temp_folder_chunks= 'temp_chunks'  # Folder that stores intermediate chunked files\n",
    "output_file = 'with_attachment_counts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b11e6352-b90c-4b23-a98c-4667a63f0bb9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To make sure that the folder exists\n",
    "os.makedirs(temp_folder_results, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "147ce180-dd02-4778-b1bf-ea4b76a8f4e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_attachment_counts(chunk_filename):\n",
    "    df = pd.read_csv(f'{temp_folder_chunks}/{chunk_filename}')\n",
    "\n",
    "    # Filter data for Sent activities\n",
    "\n",
    "    total_attachments_day = df[df['is_working_hour']].groupby(['user','day'])['attachment_count'].sum().reset_index().rename(columns={'attachment_count': 'numAttachmentDay'})\n",
    "    total_attachments_night = df[~df['is_working_hour']].groupby(['user','day'])['attachment_count'].sum().reset_index().rename(columns={'attachment_count': 'numAttachmentNight'})\n",
    "    \n",
    "    sent_data = df[df['activity'] == 'Send']\n",
    "    recieved_data = df[df['activity'] == 'View']\n",
    "\n",
    "    # Separate the data for working and non-working hours\n",
    "    sent_working_hours = sent_data[sent_data['is_working_hour']]\n",
    "    sent_off_hours = sent_data[~sent_data['is_working_hour']]\n",
    "    \n",
    "    recieved_working_hours = recieved_data[recieved_data['is_working_hour']]\n",
    "    recieved_off_hours = recieved_data[~recieved_data['is_working_hour']]\n",
    "\n",
    "    # Calculate the total number of attachments for each user on a specific day for working hours\n",
    "    sent_attachment_counts_working_hours = sent_working_hours.groupby(['user','day'])['attachment_count'].sum().reset_index().rename(columns={'attachment_count': 'numEmailSentwithAttachDay'})\n",
    "    # Calculate the total number of attachments for each user on a specific day for non-working hours\n",
    "    sent_attachment_counts_off_hours = sent_off_hours.groupby(['user','day'])['attachment_count'].sum().reset_index().rename(columns={'attachment_count': 'numEmailSentwithAttachNight'})\n",
    "\n",
    "    # Calculate the total number of attachments for each user on a specific day for working hours\n",
    "    recieved_attachment_counts_working_hours = recieved_working_hours.groupby(['user','day'])['attachment_count'].sum().reset_index().rename(columns={'attachment_count': 'numEmailRecievedwithAttachDay'})\n",
    "    # Calculate the total number of attachments for each user on a specific day for non-working hours\n",
    "    recieved_attachment_counts_off_hours = recieved_off_hours.groupby(['user','day'])['attachment_count'].sum().reset_index().rename(columns={'attachment_count': 'numEmailRecievedwithAttachNight'})\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    # Merge the results for working and non-working hours with specific suffixes\n",
    "    sent_merged_results = sent_attachment_counts_working_hours.merge(sent_attachment_counts_off_hours, on=['user','day'], how='outer', suffixes=('_working_hours', '_off_hours'))\n",
    "    sent_merged_results.fillna(0, inplace=True)  # Replace NaN with 0\n",
    "    # sent_merged_results[['numEmailSentwithAttachDay','numEmailSentwithAttachNight']] = sent_merged_results[['numEmailSentwithAttachDay','numEmailSentwithAttachNight']].astype(int)\n",
    "    \n",
    "    recieve_merged_results = recieved_attachment_counts_working_hours.merge(recieved_attachment_counts_off_hours, on=['user','day'], how='outer', suffixes=('_working_hours', '_off_hours'))\n",
    "    recieve_merged_results.fillna(0, inplace=True)  # Replace NaN with 0\n",
    "    # recieve_merged_results[['numEmailRecievedwithAttachDay','numEmailRecievedwithAttachNight']] = recieve_merged_results[['numEmailRecievedwithAttachDay','numEmailRecievedwithAttachNight']].astype(int)\n",
    "\n",
    "    merged_results = sent_merged_results.merge(recieve_merged_results, on=['user', 'day'], how='outer')\n",
    "    merged_results.fillna(0, inplace=True)\n",
    "\n",
    "    # Merge the calculated totals with the 'merged_results' DataFrame\n",
    "    merged_results = merged_results.merge(total_attachments_day, on=['user', 'day'], how='outer')\n",
    "    merged_results = merged_results.merge(total_attachments_night, on=['user', 'day'], how='outer')\n",
    "    merged_results.fillna(0, inplace=True)\n",
    "    merged_results[['numEmailRecievedwithAttachDay','numEmailRecievedwithAttachNight','numEmailSentwithAttachDay','numEmailSentwithAttachNight','numAttachmentDay','numAttachmentNight']] = merged_results[['numEmailRecievedwithAttachDay','numEmailRecievedwithAttachNight','numEmailSentwithAttachDay','numEmailSentwithAttachNight','numAttachmentDay','numAttachmentNight']].astype(int)\n",
    "\n",
    "    temp_filename = f'{temp_folder_results}/temp_result_{chunk_filename}'\n",
    "\n",
    "    # # Save the results into a CSV file\n",
    "    merged_results.to_csv(temp_filename, index=False)\n",
    "    \n",
    "    return temp_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "24ae5458-9e52-4a6a-8fae-802b26dff65d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First we have to get the list of chunks that we have in the chunks folder\n",
    "file_names = os.listdir(temp_folder_chunks)\n",
    "# Filter only files (not directories)\n",
    "chunk_filenames = [file for file in file_names if os.path.isfile(os.path.join(temp_folder_chunks, file))]\n",
    "\n",
    "# Calculate the number of emails sent and received during day and night for each chunk\n",
    "with Pool() as pool:\n",
    "    result_filenames = pool.map(calculate_attachment_counts, chunk_filenames)\n",
    "\n",
    "# Since our results are divided into different files for each day, we have to combine them\n",
    "combined_result = pd.concat([pd.read_csv(filename) for filename in result_filenames])\n",
    "\n",
    "# Save the final result to a CSV file\n",
    "combined_result.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44ae73-339e-41fb-9188-cf6a3d68e9fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # To remove the generated temp files\n",
    "# for filename in result_filenames:\n",
    "#     if os.path.exists(filename):  # Check if the file exists before removing\n",
    "#         os.remove(filename)\n",
    "#     else:\n",
    "#         print(f\"File {filename} not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
