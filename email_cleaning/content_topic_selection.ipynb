{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23e4534-7e05-4224-8c55-49a48f6a991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "098c0614-83fb-454d-9dee-0a34b371f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = 'with_content_cleaned.csv'\n",
    "img_folder = 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e1c168-158c-428b-b8ad-71bf9ffbc2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_topics = 10\n",
    "limit_topics = 50\n",
    "step_topics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e858bbf-3655-4312-83b2-dbddfee795cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDAModel(nn.Module):\n",
    "    def __init__(self, vocab_size, num_topics):\n",
    "        super(LDAModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, num_topics)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Assuming 'input' is the input document representation (e.g., Bag-of-Words)\n",
    "        topic_distribution = self.embedding(input)\n",
    "        topic_distribution = self.softmax(topic_distribution)\n",
    "        return topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e977936f-36f5-4aa8-8e00-80869c2870fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=10, step=10):\n",
    "    coherence_values = []\n",
    "\n",
    "    # Pad sequences to a consistent length\n",
    "    padded_corpus = [torch.LongTensor([entry[0] for entry in doc]) for doc in corpus]\n",
    "    padded_corpus = pad_sequence(padded_corpus, batch_first=True)\n",
    "\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LDAModel(vocab_size=len(dictionary), num_topics=num_topics)\n",
    "\n",
    "        # Move the model to GPU if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "\n",
    "        # Convert your corpus to a PyTorch tensor and move to GPU\n",
    "        input_data = padded_corpus.to(device)\n",
    "\n",
    "        # Forward pass to get the topic distribution\n",
    "        topic_distribution = model(input_data)\n",
    "\n",
    "        # Compute coherence values (dummy value, replace with actual coherence calculation)\n",
    "        coherence_values.append(torch.sum(topic_distribution).item())\n",
    "\n",
    "    return coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8065f83-416f-429e-952f-8ae209da3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the chunk\n",
    "df = pd.read_csv(input_dataset)\n",
    "    \n",
    "# Assuming 'clean_content' is the cleaned text column\n",
    "cleaned_text = df['clean_content']\n",
    "    \n",
    "# Tokenize the cleaned text\n",
    "tokenized_text = [text.split() for text in cleaned_text]\n",
    "\n",
    "del cleaned_text\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = Dictionary(tokenized_text)\n",
    "\n",
    "# Create a bag-of-words corpus\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_text]\n",
    "\n",
    "# Compute coherence values\n",
    "coherence_values = compute_coherence_values(dictionary, corpus, tokenized_text, limit_topics, start=start_topics, step=step_topics)\n",
    "\n",
    "# Plot the coherence values and save the plot\n",
    "x = range(start_topics, limit_topics, step_topics)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "    \n",
    "# Save the plot with a unique name for each chunk\n",
    "output_plot_file = os.path.join(img_folder, 'coherence_plot.png')\n",
    "plt.savefig(output_plot_file)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d09c5e7a-616a-4b04-8d95-86c1d3f87689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
