{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa72a6a-714e-4130-80b6-6acd412b5b48",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The input dataset should already have a 'day' and 'is_working_hour column' defined which we already did. It should also have already combined all the emails from to cc and bcc column separated by semicolons (;)\n",
    "# We are using the chunks that we generated using the email_chunk_generator file\n",
    "\n",
    "# The output dataset has six columns, 2 of which are user and day and 4 are calculated using this script\n",
    "# This script calculate four attributes from the email cert dataset. It generates the following attribute for each user for every single day\n",
    "# numdistinctRecipientsDay\n",
    "# numdistinctRecipientsNight\n",
    "# numinternalRecipientsDay\n",
    "# numinternalRecipientsNight\n",
    "\n",
    "# For this dataset calculation, I used HPC Cluster (Magnolia) from University of Southern Mississippi\n",
    "# In HPC clusters, I used Slrum Workload Manager, the script for which is also discussed somewhere in the repo\n",
    "\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1328b1dc-9dc4-4378-8f35-c71df7493a75",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_folder_results = 'temp_results'  # Temporary folder to store intermediate result files\n",
    "temp_folder_chunks= 'temp_chunks'  # Folder that stores intermediate chunked files\n",
    "output_file = 'with_distinct_internal_counts.csv'\n",
    "internal_domain = 'dtaa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "166b5b18-364f-4ada-9d83-da655f7f2561",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To make sure that the folder exists\n",
    "os.makedirs(temp_folder_results, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8580f929-382a-4e80-8650-727e907f0494",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_distinct_internal_counts(chunk_filename):\n",
    "    chunk = pd.read_csv(f'{temp_folder_chunks}/{chunk_filename}')\n",
    "\n",
    "    # Split recipients by semicolons and remove empty strings\n",
    "    chunk['recipients'] = chunk['recipients'].str.split(';').apply(lambda x: [email.strip() for email in x if email.strip()])\n",
    "\n",
    "    # Group by user and day\n",
    "    grouped = chunk.groupby(['user', 'day'])\n",
    "\n",
    "    # Calculate distinct emails for office hours and off-hours\n",
    "    results = []\n",
    "    for (user, day), group in grouped:\n",
    "        office_hours = group[group['is_working_hour']]\n",
    "        off_hours = group[~group['is_working_hour']]\n",
    "\n",
    "        # Count distinct emails for office hours and off-hours\n",
    "        distinct_office_hours = len(set(email for sublist in office_hours['recipients'] for email in sublist))\n",
    "        distinct_off_hours = len(set(email for sublist in off_hours['recipients'] for email in sublist))\n",
    "\n",
    "        # Count emails with 'dtaa' domain for office hours and off-hours\n",
    "        dtaa_office_hours = sum(any(internal_domain in email for email in sublist) for sublist in office_hours['recipients'])\n",
    "        dtaa_off_hours = sum(any(internal_domain in email for email in sublist) for sublist in off_hours['recipients'])\n",
    "\n",
    "        results.append({\n",
    "            'user': user,\n",
    "            'day': day,\n",
    "            'numdistinctRecipientsDay': distinct_office_hours,\n",
    "            'numdistinctRecipientsNight': distinct_off_hours,\n",
    "            'numinternalRecipientsDay': dtaa_office_hours,\n",
    "            'numinternalRecipientsNight': dtaa_off_hours\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "    # Save processed data to a new file in the temp folder\n",
    "    temp_filename = f\"{temp_folder_results}/processed_{chunk_filename}\"\n",
    "    # chunk[['day', 'user', 'numDistinctRecipientsDay', 'numDistinctRecipientsNight','numInternalRecipientsDay','numInternalRecipientsNight']].to_csv(temp_filename, index=False)\n",
    "    result_df.to_csv(temp_filename, index=False)\n",
    "    return temp_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e07ff4c9-6454-47c2-9240-3747f071de29",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user         day  numdistinctRecipientsDay  \\\n",
      "0     AAS3428  2010-01-09                         0   \n",
      "1     ABK3081  2010-01-09                         0   \n",
      "2     ABM3641  2010-01-09                         0   \n",
      "3     ABP2917  2010-01-09                         0   \n",
      "4     ACH1910  2010-01-09                         0   \n",
      "...       ...         ...                       ...   \n",
      "3965  ZVB2656  2010-01-12                         9   \n",
      "3966  ZVS1637  2010-01-12                         5   \n",
      "3967  ZWS3625  2010-01-12                         2   \n",
      "3968  ZXM3086  2010-01-12                        21   \n",
      "3969  ZZO2997  2010-01-12                        29   \n",
      "\n",
      "      numdistinctRecipientsNight  numinternalRecipientsDay  \\\n",
      "0                             32                         0   \n",
      "1                             15                         0   \n",
      "2                              2                         0   \n",
      "3                             10                         0   \n",
      "4                             16                         0   \n",
      "...                          ...                       ...   \n",
      "3965                           0                         2   \n",
      "3966                           6                         2   \n",
      "3967                           0                         1   \n",
      "3968                           0                         7   \n",
      "3969                           0                        12   \n",
      "\n",
      "      numinternalRecipientsNight  \n",
      "0                              4  \n",
      "1                              8  \n",
      "2                              0  \n",
      "3                              3  \n",
      "4                              7  \n",
      "...                          ...  \n",
      "3965                           0  \n",
      "3966                           0  \n",
      "3967                           0  \n",
      "3968                           0  \n",
      "3969                           0  \n",
      "\n",
      "[4176 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# First we have to get the list of chunks that we have in the chunks folder\n",
    "file_names = os.listdir(temp_folder_chunks)\n",
    "# # Filter only files (not directories)\n",
    "chunk_filenames = [file for file in file_names if os.path.isfile(os.path.join(temp_folder_chunks, file))]\n",
    "\n",
    "# Calculate the number of emails sent and received during day and night for each chunk\n",
    "with Pool() as pool:\n",
    "    result_filenames = pool.map(calculate_distinct_internal_counts, chunk_filenames)\n",
    "\n",
    "# Since our results are divided into different files for each day, we have to combine them\n",
    "combined_result = pd.concat([pd.read_csv(filename) for filename in result_filenames])\n",
    "\n",
    "# Save the final result to a CSV file\n",
    "print(combined_result)\n",
    "\n",
    "combined_result.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ad39f-4418-4472-bdd4-460a9a3fb025",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To remove the generated temp files\n",
    "for filename in result_filenames:\n",
    "    if os.path.exists(filename):  # Check if the file exists before removing\n",
    "        os.remove(filename)\n",
    "    else:\n",
    "        print(f\"File {filename} not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
