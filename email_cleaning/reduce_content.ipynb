{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee9a352-910b-4fdd-ac9b-84dc566f8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file generates a csv that is used for Email Content Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52778b01-7079-4a84-bf91-c3f0d0e1bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../r6.2/email.csv'  # Path to your Email dataset\n",
    "output_file = 'reduced_content_dataset.csv'  # Output file\n",
    "temp_folder_combined = 'temp_combined'  # Temporary folder to store intermediate result files\n",
    "chunk_size = 500000  # Define an appropriate chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e856f86-cf3e-4c7f-9dfc-8a5fed3df801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure that the folder exists\n",
    "os.makedirs(temp_folder_combined, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49122d-5cc6-4419-ae2c-bd3f03808344",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_hours_start = pd.to_datetime('09:00').time()\n",
    "working_hours_end = pd.to_datetime('17:00').time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218796b-9ac2-4604-aa27-583c170ae69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_working_hours(timestamp):\n",
    "    time = timestamp.time()\n",
    "    # Check if it's a weekday (Monday: 0, Tuesday: 1, ..., Friday: 4)\n",
    "    if timestamp.weekday() in range(0, 5):\n",
    "        # Check if it's working hours or not\n",
    "        if working_hours_start <= time <= working_hours_end:\n",
    "            return True\n",
    "    return False  # It's not a weekday or not within working hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54bb264a-2313-4a78-989d-2708212c6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to combine 'to', 'cc', and 'bcc' columns into 'recipients' column\n",
    "def drop_unnecessary(args):\n",
    "    chunk, index = args\n",
    "\n",
    "    # Drop the 'content' column if it exists\n",
    "    if 'to' in chunk.columns:\n",
    "        chunk = chunk.drop(columns=['to'])\n",
    "\n",
    "    if 'cc' in chunk.columns:\n",
    "        chunk = chunk.drop(columns=['cc'])\n",
    "    if 'bcc' in chunk.columns:\n",
    "        chunk = chunk.drop(columns=['bcc'])\n",
    "    if 'from' in chunk.columns:\n",
    "        chunk = chunk.drop(columns=['from'])\n",
    "    if 'activity' in chunk.columns:\n",
    "        chunk = chunk.drop(columns=['activity'])\n",
    "    if 'size' in chunk.columns:\n",
    "        chunk = chunk.drop(columns=['size'])\n",
    "    if 'attachments' in chunk.columns:\n",
    "        chunk = chunk.drop(columns=['attachments'])\n",
    "    if 'recipients' in chunk.columns:\n",
    "        chunk = chunk.drop(columns=['recipients'])\n",
    "\n",
    "\n",
    "    chunk['date'] = pd.to_datetime(chunk['date'], format='mixed')\n",
    "    chunk['is_working_hour'] = chunk['date'].apply(is_working_hours)\n",
    "    chunk['day'] = pd.to_datetime(chunk['date']).dt.date  # Extracting the date without time\n",
    "        \n",
    "    chunk.to_csv(f'{temp_folder_combined}/temp_combined_{index}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0b7e3-0dd7-440a-928a-5d71c109226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each chunk and save it into a temporary file in parallel\n",
    "with Pool() as pool:\n",
    "    chunks = [(chunk, i) for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size))]\n",
    "    pool.map(drop_unnecessary, chunks)\n",
    "\n",
    "# Merge all temporary files into one sorted file\n",
    "all_temp_files = [f'{temp_folder_combined}/temp_combined_{i}.csv' for i in range(len(chunks))]\n",
    "combined_data = pd.concat([pd.read_csv(f) for f in all_temp_files], ignore_index=True)\n",
    "combined_data.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d68b6b-6d15-42bd-bed4-eafc133c9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary files\n",
    "for f in all_temp_files:\n",
    "    os.remove(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
